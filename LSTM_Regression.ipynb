{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of LSTM_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1jfE2HBU502XvoHzdue_E435tYQOwYPpb",
      "authorship_tag": "ABX9TyMzvrCMoe2UlPJE8+1GEsyr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurabh-1991/DeepLearning-Algorithms/blob/master/LSTM_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCpgKnIR2t4n"
      },
      "source": [
        "#Input Required Libraries\n",
        "from math import sqrt\n",
        "import pandas as pd\n",
        "from numpy import concatenate\n",
        "from matplotlib import pyplot\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from keras.layers import Dense,Dropout\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31LKxK8C53af",
        "outputId": "9f723177-e5fa-4533-e996-75f162dd5432"
      },
      "source": [
        "# Read in data and display first 5 rows\n",
        "features = pd.read_csv('Dataset2.csv')\n",
        "print('The shape of our features is:', features.shape)\n",
        "features.head(5)\n",
        "X = features.iloc[:,1:-4]\n",
        "Y = features.iloc[:,-4:]\n",
        "# Scaling the dataset to fit the model\n",
        "sc = StandardScaler()\n",
        "X_scale = sc.fit_transform(X)\n",
        "# Dividing the data into training and testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scale, Y, test_size = 0.20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of our features is: (114627, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9y2pzOy98YKE",
        "outputId": "d7ec531d-ceaf-45dd-8306-fe88bc763e16"
      },
      "source": [
        "y_train = y_train.to_numpy()\n",
        "# y_test = y_test.to_numpy()\n",
        "print(f\"\\nShape of X_train:-{X_train.shape} Type -{type(X_train)}\")\n",
        "print(f\"\\nShape of y_train:-{y_train.shape} Type -{type(y_train)}\")\n",
        "print(\"\\nShape of X_test:-\",X_test.shape)\n",
        "print(\"\\nShape of y_test:-\",y_test.shape)\n",
        "#y_train = y_train.to_numpy()\n",
        "#y_test = y_test.to_numpy()\n",
        "#print(f\"\\nShape of y_train_Conv:-{y_train.shape} Type -{type(y_train)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of X_train:-(91701, 11) Type -<class 'numpy.ndarray'>\n",
            "\n",
            "Shape of y_train:-(91701, 4) Type -<class 'numpy.ndarray'>\n",
            "\n",
            "Shape of X_test:- (22926, 11)\n",
            "\n",
            "Shape of y_test:- (22926, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-VrSR1m-pu4",
        "outputId": "b34858bb-d55d-481e-9df3-48c4958178b3"
      },
      "source": [
        "#making Data compatible with LSTM\n",
        "x_train = X_train.reshape(-1, 1, 11)\n",
        "x_test  = X_test.reshape(-1, 1, 11)\n",
        "Y_train = y_train.reshape(-1,1,4)\n",
        "Y_test = y_test.reshape(-1, 1, 4)\n",
        "\n",
        "print(\"\\nShape of X_train:-\",x_train.shape)\n",
        "print(\"\\nShape of Y_train:-\",Y_train.shape)\n",
        "print(\"\\nShape of X_test:-\",x_test.shape)\n",
        "print(\"\\nShape of Y_test:-\",Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of X_train:- (91701, 1, 11)\n",
            "\n",
            "Shape of Y_train:- (91701, 1, 4)\n",
            "\n",
            "Shape of X_test:- (22926, 1, 11)\n",
            "\n",
            "Shape of Y_test:- (22926, 1, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwILApcqqBeJ"
      },
      "source": [
        "**Model Architecture**\n",
        "\n",
        "Define the LSTM with 100 neurons in the first hidden layer and 1 neuron in the output layer for predicting Global_active_power. The input shape will be 1 time step with 11 features.\n",
        "Dropout 20%.\n",
        "Use the MSE loss function and the efficient Adam version of stochastic gradient descent.\n",
        "The model will be fit for 200 training epochs with a batch size of 50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOhhKOp67tIT",
        "outputId": "89d3838e-a718-46f9-c6d6-83c53f88ca0e"
      },
      "source": [
        "# design network\n",
        "model = Sequential()\n",
        "model.add(LSTM(100,return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2]),))\n",
        "model.add(Dropout(0.5))\n",
        "# model.add(LSTM(20,return_sequences=False))\n",
        "# model.add(Dropout(0.5))\n",
        "model.add(Dense(4))\n",
        "model.compile(loss='mae', optimizer='adam',metrics=['accuracy'])\n",
        "#Save Weights and Model\n",
        "checkpoint_filepath = '/content/drive/MyDrive/LSTM_Project/firstModel.hdf5'\n",
        "model_checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath,save_weights_only=True,monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "# fit network\n",
        "history = model.fit(x_train, Y_train, epochs=200,batch_size=50,\n",
        "                    validation_data=(x_test,Y_test),\n",
        "                    callbacks=[model_checkpoint_callback],verbose=1)\n",
        "model.load_weights(checkpoint_filepath)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1835/1835 [==============================] - 9s 4ms/step - loss: 8.6361 - accuracy: 0.3352 - val_loss: 1.2771 - val_accuracy: 0.7108\n",
            "Epoch 2/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 3.3628 - accuracy: 0.4073 - val_loss: 1.2480 - val_accuracy: 0.7141\n",
            "Epoch 3/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 3.1483 - accuracy: 0.5734 - val_loss: 1.1559 - val_accuracy: 0.7146\n",
            "Epoch 4/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 2.8795 - accuracy: 0.6922 - val_loss: 1.2007 - val_accuracy: 0.7147\n",
            "Epoch 5/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 2.6652 - accuracy: 0.7182 - val_loss: 1.1715 - val_accuracy: 0.7146\n",
            "Epoch 6/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 2.5229 - accuracy: 0.7180 - val_loss: 1.1849 - val_accuracy: 0.7206\n",
            "Epoch 7/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 2.4307 - accuracy: 0.7198 - val_loss: 1.1836 - val_accuracy: 0.7288\n",
            "Epoch 8/200\n",
            "1835/1835 [==============================] - 6s 3ms/step - loss: 2.3596 - accuracy: 0.7203 - val_loss: 1.1052 - val_accuracy: 0.7167\n",
            "Epoch 9/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 2.2950 - accuracy: 0.7158 - val_loss: 1.0437 - val_accuracy: 0.7146\n",
            "Epoch 10/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 2.2209 - accuracy: 0.7164 - val_loss: 1.1150 - val_accuracy: 0.7146\n",
            "Epoch 11/200\n",
            "1835/1835 [==============================] - 6s 4ms/step - loss: 2.1710 - accuracy: 0.7183 - val_loss: 1.0218 - val_accuracy: 0.7146\n",
            "Epoch 12/200\n",
            "1835/1835 [==============================] - 6s 3ms/step - loss: 2.1024 - accuracy: 0.7181 - val_loss: 1.0780 - val_accuracy: 0.7146\n",
            "Epoch 13/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 2.0596 - accuracy: 0.7190 - val_loss: 1.1525 - val_accuracy: 0.7146\n",
            "Epoch 14/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 1.9967 - accuracy: 0.7172 - val_loss: 1.1108 - val_accuracy: 0.7146\n",
            "Epoch 15/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 1.9448 - accuracy: 0.7160 - val_loss: 1.0620 - val_accuracy: 0.7146\n",
            "Epoch 16/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 1.8976 - accuracy: 0.7172 - val_loss: 1.0196 - val_accuracy: 0.7146\n",
            "Epoch 17/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 1.8435 - accuracy: 0.7170 - val_loss: 0.9514 - val_accuracy: 0.7146\n",
            "Epoch 18/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 1.7914 - accuracy: 0.7175 - val_loss: 0.9912 - val_accuracy: 0.7146\n",
            "Epoch 19/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 1.7445 - accuracy: 0.7173 - val_loss: 1.0267 - val_accuracy: 0.7146\n",
            "Epoch 20/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 1.6969 - accuracy: 0.7182 - val_loss: 0.9865 - val_accuracy: 0.7146\n",
            "Epoch 21/200\n",
            "1835/1835 [==============================] - 6s 3ms/step - loss: 1.6410 - accuracy: 0.7167 - val_loss: 0.9535 - val_accuracy: 0.7146\n",
            "Epoch 22/200\n",
            "1835/1835 [==============================] - 6s 3ms/step - loss: 1.5992 - accuracy: 0.7174 - val_loss: 0.9900 - val_accuracy: 0.7146\n",
            "Epoch 23/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 1.5557 - accuracy: 0.7132 - val_loss: 0.9710 - val_accuracy: 0.7146\n",
            "Epoch 24/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 1.5047 - accuracy: 0.7127 - val_loss: 0.9706 - val_accuracy: 0.7150\n",
            "Epoch 25/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 1.4733 - accuracy: 0.7076 - val_loss: 0.9486 - val_accuracy: 0.7145\n",
            "Epoch 26/200\n",
            "1835/1835 [==============================] - 6s 3ms/step - loss: 1.4303 - accuracy: 0.7067 - val_loss: 0.9130 - val_accuracy: 0.7141\n",
            "Epoch 27/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 1.3878 - accuracy: 0.7050 - val_loss: 0.9117 - val_accuracy: 0.7146\n",
            "Epoch 28/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 1.3394 - accuracy: 0.7033 - val_loss: 0.9428 - val_accuracy: 0.7119\n",
            "Epoch 29/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 1.3069 - accuracy: 0.7004 - val_loss: 0.9309 - val_accuracy: 0.7031\n",
            "Epoch 30/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 1.2644 - accuracy: 0.6927 - val_loss: 0.8777 - val_accuracy: 0.7129\n",
            "Epoch 31/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 1.2268 - accuracy: 0.6850 - val_loss: 0.8404 - val_accuracy: 0.7050\n",
            "Epoch 32/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 1.1885 - accuracy: 0.6739 - val_loss: 0.8397 - val_accuracy: 0.7126\n",
            "Epoch 33/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 1.1531 - accuracy: 0.6665 - val_loss: 0.8528 - val_accuracy: 0.7118\n",
            "Epoch 34/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 1.1177 - accuracy: 0.6563 - val_loss: 0.8122 - val_accuracy: 0.6728\n",
            "Epoch 35/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 1.0875 - accuracy: 0.6482 - val_loss: 0.8359 - val_accuracy: 0.6918\n",
            "Epoch 36/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 1.0555 - accuracy: 0.6398 - val_loss: 0.8287 - val_accuracy: 0.6847\n",
            "Epoch 37/200\n",
            "1835/1835 [==============================] - 6s 4ms/step - loss: 1.0224 - accuracy: 0.6349 - val_loss: 0.8064 - val_accuracy: 0.6706\n",
            "Epoch 38/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.9913 - accuracy: 0.6270 - val_loss: 0.8001 - val_accuracy: 0.6728\n",
            "Epoch 39/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.9671 - accuracy: 0.6193 - val_loss: 0.8070 - val_accuracy: 0.6793\n",
            "Epoch 40/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.9390 - accuracy: 0.6115 - val_loss: 0.7616 - val_accuracy: 0.6842\n",
            "Epoch 41/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.9134 - accuracy: 0.6063 - val_loss: 0.7586 - val_accuracy: 0.6405\n",
            "Epoch 42/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.8919 - accuracy: 0.6035 - val_loss: 0.7608 - val_accuracy: 0.6573\n",
            "Epoch 43/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.8683 - accuracy: 0.6005 - val_loss: 0.7533 - val_accuracy: 0.6529\n",
            "Epoch 44/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.8498 - accuracy: 0.6025 - val_loss: 0.7461 - val_accuracy: 0.6425\n",
            "Epoch 45/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.8320 - accuracy: 0.6019 - val_loss: 0.7435 - val_accuracy: 0.5992\n",
            "Epoch 46/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.8161 - accuracy: 0.6019 - val_loss: 0.7406 - val_accuracy: 0.6217\n",
            "Epoch 47/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.8021 - accuracy: 0.6034 - val_loss: 0.7346 - val_accuracy: 0.6293\n",
            "Epoch 48/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.7922 - accuracy: 0.6029 - val_loss: 0.7359 - val_accuracy: 0.5895\n",
            "Epoch 49/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.7821 - accuracy: 0.6038 - val_loss: 0.7331 - val_accuracy: 0.6100\n",
            "Epoch 50/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.7735 - accuracy: 0.6053 - val_loss: 0.7249 - val_accuracy: 0.6128\n",
            "Epoch 51/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.7674 - accuracy: 0.6111 - val_loss: 0.7213 - val_accuracy: 0.6064\n",
            "Epoch 52/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.7614 - accuracy: 0.6153 - val_loss: 0.7176 - val_accuracy: 0.6151\n",
            "Epoch 53/200\n",
            "1835/1835 [==============================] - 6s 4ms/step - loss: 0.7553 - accuracy: 0.6186 - val_loss: 0.7120 - val_accuracy: 0.6215\n",
            "Epoch 54/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.7518 - accuracy: 0.6228 - val_loss: 0.7071 - val_accuracy: 0.6304\n",
            "Epoch 55/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.7468 - accuracy: 0.6269 - val_loss: 0.7079 - val_accuracy: 0.6251\n",
            "Epoch 56/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.7425 - accuracy: 0.6290 - val_loss: 0.6995 - val_accuracy: 0.6372\n",
            "Epoch 57/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.7399 - accuracy: 0.6334 - val_loss: 0.6970 - val_accuracy: 0.6319\n",
            "Epoch 58/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.7367 - accuracy: 0.6375 - val_loss: 0.6922 - val_accuracy: 0.6494\n",
            "Epoch 59/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.7319 - accuracy: 0.6419 - val_loss: 0.6909 - val_accuracy: 0.6563\n",
            "Epoch 60/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.7284 - accuracy: 0.6462 - val_loss: 0.6858 - val_accuracy: 0.6533\n",
            "Epoch 61/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.7264 - accuracy: 0.6474 - val_loss: 0.6826 - val_accuracy: 0.6549\n",
            "Epoch 62/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.7227 - accuracy: 0.6476 - val_loss: 0.6812 - val_accuracy: 0.6676\n",
            "Epoch 63/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.7189 - accuracy: 0.6520 - val_loss: 0.6757 - val_accuracy: 0.6675\n",
            "Epoch 64/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.7165 - accuracy: 0.6529 - val_loss: 0.6737 - val_accuracy: 0.6643\n",
            "Epoch 65/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.7120 - accuracy: 0.6557 - val_loss: 0.6703 - val_accuracy: 0.6689\n",
            "Epoch 66/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.7103 - accuracy: 0.6614 - val_loss: 0.6661 - val_accuracy: 0.6681\n",
            "Epoch 67/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.7075 - accuracy: 0.6654 - val_loss: 0.6627 - val_accuracy: 0.6717\n",
            "Epoch 68/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.7043 - accuracy: 0.6672 - val_loss: 0.6641 - val_accuracy: 0.6653\n",
            "Epoch 69/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.7025 - accuracy: 0.6660 - val_loss: 0.6571 - val_accuracy: 0.6722\n",
            "Epoch 70/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.7001 - accuracy: 0.6700 - val_loss: 0.6576 - val_accuracy: 0.6804\n",
            "Epoch 71/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6987 - accuracy: 0.6705 - val_loss: 0.6548 - val_accuracy: 0.6697\n",
            "Epoch 72/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6979 - accuracy: 0.6698 - val_loss: 0.6535 - val_accuracy: 0.6794\n",
            "Epoch 73/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6944 - accuracy: 0.6699 - val_loss: 0.6504 - val_accuracy: 0.6763\n",
            "Epoch 74/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6937 - accuracy: 0.6714 - val_loss: 0.6470 - val_accuracy: 0.6787\n",
            "Epoch 75/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6922 - accuracy: 0.6720 - val_loss: 0.6456 - val_accuracy: 0.6832\n",
            "Epoch 76/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6894 - accuracy: 0.6740 - val_loss: 0.6444 - val_accuracy: 0.6800\n",
            "Epoch 77/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6892 - accuracy: 0.6760 - val_loss: 0.6435 - val_accuracy: 0.6809\n",
            "Epoch 78/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6879 - accuracy: 0.6768 - val_loss: 0.6422 - val_accuracy: 0.6780\n",
            "Epoch 79/200\n",
            "1835/1835 [==============================] - 6s 4ms/step - loss: 0.6867 - accuracy: 0.6766 - val_loss: 0.6377 - val_accuracy: 0.6797\n",
            "Epoch 80/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6848 - accuracy: 0.6787 - val_loss: 0.6409 - val_accuracy: 0.6896\n",
            "Epoch 81/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6833 - accuracy: 0.6771 - val_loss: 0.6364 - val_accuracy: 0.6830\n",
            "Epoch 82/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6827 - accuracy: 0.6779 - val_loss: 0.6374 - val_accuracy: 0.6776\n",
            "Epoch 83/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6811 - accuracy: 0.6798 - val_loss: 0.6380 - val_accuracy: 0.6822\n",
            "Epoch 84/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6808 - accuracy: 0.6807 - val_loss: 0.6347 - val_accuracy: 0.6870\n",
            "Epoch 85/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6789 - accuracy: 0.6830 - val_loss: 0.6316 - val_accuracy: 0.6921\n",
            "Epoch 86/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6785 - accuracy: 0.6833 - val_loss: 0.6329 - val_accuracy: 0.6907\n",
            "Epoch 87/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6785 - accuracy: 0.6828 - val_loss: 0.6282 - val_accuracy: 0.6866\n",
            "Epoch 88/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6771 - accuracy: 0.6807 - val_loss: 0.6302 - val_accuracy: 0.6876\n",
            "Epoch 89/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6754 - accuracy: 0.6841 - val_loss: 0.6274 - val_accuracy: 0.6908\n",
            "Epoch 90/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6747 - accuracy: 0.6856 - val_loss: 0.6283 - val_accuracy: 0.6941\n",
            "Epoch 91/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6732 - accuracy: 0.6871 - val_loss: 0.6264 - val_accuracy: 0.6890\n",
            "Epoch 92/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6723 - accuracy: 0.6881 - val_loss: 0.6267 - val_accuracy: 0.6987\n",
            "Epoch 93/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6722 - accuracy: 0.6869 - val_loss: 0.6238 - val_accuracy: 0.6925\n",
            "Epoch 94/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6707 - accuracy: 0.6904 - val_loss: 0.6221 - val_accuracy: 0.6962\n",
            "Epoch 95/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6700 - accuracy: 0.6904 - val_loss: 0.6222 - val_accuracy: 0.6924\n",
            "Epoch 96/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6696 - accuracy: 0.6901 - val_loss: 0.6200 - val_accuracy: 0.6924\n",
            "Epoch 97/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6684 - accuracy: 0.6913 - val_loss: 0.6189 - val_accuracy: 0.6999\n",
            "Epoch 98/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6675 - accuracy: 0.6899 - val_loss: 0.6186 - val_accuracy: 0.6982\n",
            "Epoch 99/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6657 - accuracy: 0.6931 - val_loss: 0.6174 - val_accuracy: 0.6948\n",
            "Epoch 100/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6659 - accuracy: 0.6921 - val_loss: 0.6154 - val_accuracy: 0.7025\n",
            "Epoch 101/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6649 - accuracy: 0.6935 - val_loss: 0.6144 - val_accuracy: 0.6923\n",
            "Epoch 102/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6654 - accuracy: 0.6936 - val_loss: 0.6191 - val_accuracy: 0.7026\n",
            "Epoch 103/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6633 - accuracy: 0.6939 - val_loss: 0.6133 - val_accuracy: 0.7006\n",
            "Epoch 104/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6631 - accuracy: 0.6927 - val_loss: 0.6130 - val_accuracy: 0.6988\n",
            "Epoch 105/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6637 - accuracy: 0.6962 - val_loss: 0.6099 - val_accuracy: 0.6965\n",
            "Epoch 106/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6617 - accuracy: 0.6956 - val_loss: 0.6133 - val_accuracy: 0.7011\n",
            "Epoch 107/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6608 - accuracy: 0.6951 - val_loss: 0.6132 - val_accuracy: 0.7023\n",
            "Epoch 108/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6580 - accuracy: 0.6957 - val_loss: 0.6107 - val_accuracy: 0.6956\n",
            "Epoch 109/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6599 - accuracy: 0.6953 - val_loss: 0.6076 - val_accuracy: 0.6975\n",
            "Epoch 110/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6585 - accuracy: 0.6967 - val_loss: 0.6070 - val_accuracy: 0.7092\n",
            "Epoch 111/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6585 - accuracy: 0.6965 - val_loss: 0.6078 - val_accuracy: 0.7045\n",
            "Epoch 112/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6577 - accuracy: 0.6963 - val_loss: 0.6043 - val_accuracy: 0.7036\n",
            "Epoch 113/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6563 - accuracy: 0.6964 - val_loss: 0.6048 - val_accuracy: 0.6996\n",
            "Epoch 114/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6544 - accuracy: 0.6976 - val_loss: 0.6016 - val_accuracy: 0.7050\n",
            "Epoch 115/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6556 - accuracy: 0.6985 - val_loss: 0.6066 - val_accuracy: 0.7056\n",
            "Epoch 116/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6542 - accuracy: 0.7007 - val_loss: 0.6045 - val_accuracy: 0.7107\n",
            "Epoch 117/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6540 - accuracy: 0.6993 - val_loss: 0.6013 - val_accuracy: 0.7054\n",
            "Epoch 118/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6535 - accuracy: 0.6972 - val_loss: 0.6016 - val_accuracy: 0.7105\n",
            "Epoch 119/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6521 - accuracy: 0.6978 - val_loss: 0.6035 - val_accuracy: 0.7041\n",
            "Epoch 120/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6513 - accuracy: 0.7005 - val_loss: 0.5987 - val_accuracy: 0.7080\n",
            "Epoch 121/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6512 - accuracy: 0.6991 - val_loss: 0.5986 - val_accuracy: 0.7042\n",
            "Epoch 122/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6504 - accuracy: 0.6997 - val_loss: 0.5965 - val_accuracy: 0.7060\n",
            "Epoch 123/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6493 - accuracy: 0.7020 - val_loss: 0.5964 - val_accuracy: 0.7080\n",
            "Epoch 124/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6492 - accuracy: 0.7028 - val_loss: 0.5984 - val_accuracy: 0.7110\n",
            "Epoch 125/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6496 - accuracy: 0.7019 - val_loss: 0.5995 - val_accuracy: 0.7077\n",
            "Epoch 126/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6478 - accuracy: 0.7013 - val_loss: 0.5968 - val_accuracy: 0.7044\n",
            "Epoch 127/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6476 - accuracy: 0.7000 - val_loss: 0.5934 - val_accuracy: 0.7150\n",
            "Epoch 128/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6468 - accuracy: 0.7024 - val_loss: 0.5939 - val_accuracy: 0.7051\n",
            "Epoch 129/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6462 - accuracy: 0.7037 - val_loss: 0.5928 - val_accuracy: 0.7106\n",
            "Epoch 130/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6452 - accuracy: 0.7008 - val_loss: 0.5930 - val_accuracy: 0.7169\n",
            "Epoch 131/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6450 - accuracy: 0.7034 - val_loss: 0.5932 - val_accuracy: 0.7108\n",
            "Epoch 132/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6452 - accuracy: 0.7043 - val_loss: 0.5945 - val_accuracy: 0.7086\n",
            "Epoch 133/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6429 - accuracy: 0.7051 - val_loss: 0.5876 - val_accuracy: 0.7093\n",
            "Epoch 134/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6424 - accuracy: 0.7040 - val_loss: 0.5899 - val_accuracy: 0.7142\n",
            "Epoch 135/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6431 - accuracy: 0.7049 - val_loss: 0.5880 - val_accuracy: 0.7092\n",
            "Epoch 136/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6437 - accuracy: 0.7029 - val_loss: 0.5857 - val_accuracy: 0.7108\n",
            "Epoch 137/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6424 - accuracy: 0.7029 - val_loss: 0.5884 - val_accuracy: 0.7087\n",
            "Epoch 138/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6412 - accuracy: 0.7035 - val_loss: 0.5836 - val_accuracy: 0.7179\n",
            "Epoch 139/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6421 - accuracy: 0.7041 - val_loss: 0.5867 - val_accuracy: 0.7092\n",
            "Epoch 140/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6398 - accuracy: 0.7044 - val_loss: 0.5852 - val_accuracy: 0.7123\n",
            "Epoch 141/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6403 - accuracy: 0.7044 - val_loss: 0.5860 - val_accuracy: 0.7102\n",
            "Epoch 142/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6397 - accuracy: 0.7044 - val_loss: 0.5807 - val_accuracy: 0.7010\n",
            "Epoch 143/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6390 - accuracy: 0.7067 - val_loss: 0.5859 - val_accuracy: 0.7178\n",
            "Epoch 144/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6382 - accuracy: 0.7048 - val_loss: 0.5839 - val_accuracy: 0.7211\n",
            "Epoch 145/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6361 - accuracy: 0.7076 - val_loss: 0.5823 - val_accuracy: 0.7127\n",
            "Epoch 146/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6371 - accuracy: 0.7059 - val_loss: 0.5819 - val_accuracy: 0.7134\n",
            "Epoch 147/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6370 - accuracy: 0.7054 - val_loss: 0.5839 - val_accuracy: 0.7101\n",
            "Epoch 148/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6378 - accuracy: 0.7034 - val_loss: 0.5792 - val_accuracy: 0.7162\n",
            "Epoch 149/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6369 - accuracy: 0.7054 - val_loss: 0.5778 - val_accuracy: 0.7173\n",
            "Epoch 150/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6366 - accuracy: 0.7066 - val_loss: 0.5760 - val_accuracy: 0.7153\n",
            "Epoch 151/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6359 - accuracy: 0.7058 - val_loss: 0.5785 - val_accuracy: 0.7210\n",
            "Epoch 152/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6348 - accuracy: 0.7077 - val_loss: 0.5780 - val_accuracy: 0.7228\n",
            "Epoch 153/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6348 - accuracy: 0.7035 - val_loss: 0.5766 - val_accuracy: 0.7153\n",
            "Epoch 154/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6346 - accuracy: 0.7060 - val_loss: 0.5779 - val_accuracy: 0.7198\n",
            "Epoch 155/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6332 - accuracy: 0.7063 - val_loss: 0.5751 - val_accuracy: 0.7120\n",
            "Epoch 156/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6335 - accuracy: 0.7077 - val_loss: 0.5771 - val_accuracy: 0.7218\n",
            "Epoch 157/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6332 - accuracy: 0.7070 - val_loss: 0.5769 - val_accuracy: 0.7240\n",
            "Epoch 158/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6319 - accuracy: 0.7062 - val_loss: 0.5746 - val_accuracy: 0.7109\n",
            "Epoch 159/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6324 - accuracy: 0.7071 - val_loss: 0.5749 - val_accuracy: 0.7142\n",
            "Epoch 160/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6305 - accuracy: 0.7082 - val_loss: 0.5742 - val_accuracy: 0.7192\n",
            "Epoch 161/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6330 - accuracy: 0.7057 - val_loss: 0.5735 - val_accuracy: 0.7193\n",
            "Epoch 162/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6318 - accuracy: 0.7050 - val_loss: 0.5749 - val_accuracy: 0.7224\n",
            "Epoch 163/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6292 - accuracy: 0.7069 - val_loss: 0.5733 - val_accuracy: 0.7221\n",
            "Epoch 164/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6299 - accuracy: 0.7088 - val_loss: 0.5719 - val_accuracy: 0.7215\n",
            "Epoch 165/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6300 - accuracy: 0.7066 - val_loss: 0.5703 - val_accuracy: 0.7146\n",
            "Epoch 166/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6294 - accuracy: 0.7077 - val_loss: 0.5702 - val_accuracy: 0.7266\n",
            "Epoch 167/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6293 - accuracy: 0.7072 - val_loss: 0.5700 - val_accuracy: 0.7189\n",
            "Epoch 168/200\n",
            "1835/1835 [==============================] - 8s 4ms/step - loss: 0.6300 - accuracy: 0.7063 - val_loss: 0.5703 - val_accuracy: 0.7191\n",
            "Epoch 169/200\n",
            "1835/1835 [==============================] - 9s 5ms/step - loss: 0.6289 - accuracy: 0.7059 - val_loss: 0.5677 - val_accuracy: 0.7228\n",
            "Epoch 170/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6280 - accuracy: 0.7091 - val_loss: 0.5742 - val_accuracy: 0.7130\n",
            "Epoch 171/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6285 - accuracy: 0.7071 - val_loss: 0.5672 - val_accuracy: 0.7187\n",
            "Epoch 172/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6277 - accuracy: 0.7098 - val_loss: 0.5659 - val_accuracy: 0.7160\n",
            "Epoch 173/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6272 - accuracy: 0.7061 - val_loss: 0.5669 - val_accuracy: 0.7226\n",
            "Epoch 174/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6265 - accuracy: 0.7072 - val_loss: 0.5666 - val_accuracy: 0.7170\n",
            "Epoch 175/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6272 - accuracy: 0.7074 - val_loss: 0.5700 - val_accuracy: 0.7252\n",
            "Epoch 176/200\n",
            "1835/1835 [==============================] - 8s 4ms/step - loss: 0.6264 - accuracy: 0.7084 - val_loss: 0.5696 - val_accuracy: 0.7219\n",
            "Epoch 177/200\n",
            "1835/1835 [==============================] - 8s 4ms/step - loss: 0.6262 - accuracy: 0.7078 - val_loss: 0.5661 - val_accuracy: 0.7209\n",
            "Epoch 178/200\n",
            "1835/1835 [==============================] - 8s 4ms/step - loss: 0.6269 - accuracy: 0.7083 - val_loss: 0.5675 - val_accuracy: 0.7132\n",
            "Epoch 179/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6242 - accuracy: 0.7067 - val_loss: 0.5642 - val_accuracy: 0.7214\n",
            "Epoch 180/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6262 - accuracy: 0.7091 - val_loss: 0.5678 - val_accuracy: 0.7265\n",
            "Epoch 181/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6248 - accuracy: 0.7100 - val_loss: 0.5641 - val_accuracy: 0.7158\n",
            "Epoch 182/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6244 - accuracy: 0.7110 - val_loss: 0.5662 - val_accuracy: 0.7206\n",
            "Epoch 183/200\n",
            "1835/1835 [==============================] - 8s 4ms/step - loss: 0.6236 - accuracy: 0.7115 - val_loss: 0.5647 - val_accuracy: 0.7165\n",
            "Epoch 184/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6247 - accuracy: 0.7112 - val_loss: 0.5637 - val_accuracy: 0.7259\n",
            "Epoch 185/200\n",
            "1835/1835 [==============================] - 8s 4ms/step - loss: 0.6231 - accuracy: 0.7099 - val_loss: 0.5640 - val_accuracy: 0.7201\n",
            "Epoch 186/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6232 - accuracy: 0.7088 - val_loss: 0.5616 - val_accuracy: 0.7243\n",
            "Epoch 187/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6229 - accuracy: 0.7087 - val_loss: 0.5615 - val_accuracy: 0.7189\n",
            "Epoch 188/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6221 - accuracy: 0.7089 - val_loss: 0.5659 - val_accuracy: 0.7265\n",
            "Epoch 189/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6218 - accuracy: 0.7098 - val_loss: 0.5601 - val_accuracy: 0.7272\n",
            "Epoch 190/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6218 - accuracy: 0.7097 - val_loss: 0.5603 - val_accuracy: 0.7178\n",
            "Epoch 191/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6217 - accuracy: 0.7102 - val_loss: 0.5588 - val_accuracy: 0.7204\n",
            "Epoch 192/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6220 - accuracy: 0.7111 - val_loss: 0.5612 - val_accuracy: 0.7279\n",
            "Epoch 193/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6226 - accuracy: 0.7106 - val_loss: 0.5600 - val_accuracy: 0.7168\n",
            "Epoch 194/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6215 - accuracy: 0.7089 - val_loss: 0.5589 - val_accuracy: 0.7320\n",
            "Epoch 195/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6203 - accuracy: 0.7122 - val_loss: 0.5609 - val_accuracy: 0.7121\n",
            "Epoch 196/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6216 - accuracy: 0.7103 - val_loss: 0.5601 - val_accuracy: 0.7174\n",
            "Epoch 197/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6212 - accuracy: 0.7112 - val_loss: 0.5588 - val_accuracy: 0.7200\n",
            "Epoch 198/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6202 - accuracy: 0.7125 - val_loss: 0.5601 - val_accuracy: 0.7351\n",
            "Epoch 199/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6188 - accuracy: 0.7124 - val_loss: 0.5616 - val_accuracy: 0.7192\n",
            "Epoch 200/200\n",
            "1835/1835 [==============================] - 7s 4ms/step - loss: 0.6189 - accuracy: 0.7119 - val_loss: 0.5605 - val_accuracy: 0.7227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ijzaD4QJm1c",
        "outputId": "a7095f98-642a-4143-9023-2d9fd95b02ae"
      },
      "source": [
        "#Accuracy\n",
        "#print(\"\\nModel Accuracy = \"history.history['accuracy'])\n",
        "import numpy as np\n",
        "best_model_accuracy = history.history['accuracy'][np.argmin(history.history['loss'])]\n",
        "print(\"Model Best Accuracy =\",best_model_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Best Accuracy = 0.7124350070953369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "_hFswYQa5-at",
        "outputId": "9f8d2e09-38a6-4c69-d688-3fbc8ac84939"
      },
      "source": [
        "# plot history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD7CAYAAABDld6xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwc9X3/8ddndlenb0kGbOPYHOEywTaCmEA4QiCYJIYcpYSQQJNfzK9JGyi/0MCjuWh/v5SkTUrTEKhpaEIgpAnHD8pVQ2pDCOGQD4KxjQ8wWDbYxsaHLOvY3U//mFlpddkrWasdW+/n47GPnZ2d3f3sSHrPV9/5zoy5OyIiEl9BqQsQEZG9U1CLiMScglpEJOYU1CIiMaegFhGJOQW1iEjMFRTUZna1mS0zs1fM7JpiFyUiIp32GdRmNg34EnAqcBLwMTM7qtiFiYhIKFnAMscBz7t7M4CZPQV8Evh+Xy+ora31KVOmDEqBIiLDwaJFi95x97reniskqJcB/8/MaoA9wIVAQ/eFzGwuMBdg8uTJNDT0WERERPpgZm/09dw+uz7cfQXwPWA+8DiwFMj0stw8d6939/q6ul43CiIiMgAF7Ux095+6+8nufibwLrCquGWJiEhOIV0fmNl4d99sZpMJ+6dnFbcsERHJKSiogfuiPup24Cvuvr2INYnIMNTe3k5jYyMtLS2lLqWoKioqmDRpEqlUquDXFBTU7v7BAVclIlKAxsZGRo4cyZQpUzCzUpdTFO7O1q1baWxsZOrUqQW/TkcmikgstLS0UFNTc9CGNICZUVNT0+//GhTUIhIbB3NI5wzkO8YqqH/029U8tWpLqcsQEYmVWAX1rQvX8sxqBbWIDL3t27fzk5/8pN+vu/DCC9m+vbjjK2IV1InAyGRLXYWIDEd9BXU6nd7r6x599FHGjBlTrLKAwofnDYnAIKuL7YpICVx//fWsXbuW6dOnk0qlqKioYOzYsaxcuZJVq1Zx8cUXs379elpaWrj66quZO3cuAFOmTKGhoYGmpiZmz57NGWecwbPPPsvEiRN58MEHqays3O/aYhXUYYtaQS0y3N34n6+wfOPOQX3P4yeM4tsfP6HP52+66SaWLVvG0qVLWbhwIR/96EdZtmxZxzC6O+64g3HjxrFnzx5OOeUUPvWpT1FTU9PlPVavXs0999zD7bffziWXXMJ9993H5Zdfvt+1xy+o1aIWkRg49dRTu4x1/tGPfsQDDzwAwPr161m9enWPoJ46dSrTp08H4OSTT2bdunWDUkusgjowI6sWtciwt7eW71Cprq7umF64cCFPPvkkf/jDH6iqquLss8/udSx0eXl5x3QikWDPnj2DUksMdyYqqEVk6I0cOZJdu3b1+tyOHTsYO3YsVVVVrFy5kueee25Ia4tdi1pdHyJSCjU1NZx++ulMmzaNyspKDjnkkI7nLrjgAm677TaOO+44jjnmGGbNGtrz0sUqqBOBuj5EpHR++ctf9jq/vLycxx57rNfncv3QtbW1LFu2rGP+1772tUGrK35dH8ppEZEuYhXUgaEWtYhIN7EKau1MFBHpKVZBrZ2JIiI9FRTUZvZXZvaKmS0zs3vMrKIYxSQT2pkoItLdPoPazCYCXwXq3X0akAAuLUYxCbWoRUR6KLTrIwlUmlkSqAI2FqUY9VGLSIkM9DSnADfffDPNzc2DXFGnfQa1u28A/hF4E3gL2OHu87svZ2ZzzazBzBq2bBnYOaUTpqAWkdKIc1Dv84AXMxsLXARMBbYDvzGzy939rvzl3H0eMA+gvr5+QGmrFrWIlEr+aU7PO+88xo8fz69//WtaW1v5xCc+wY033sju3bu55JJLaGxsJJPJ8M1vfpNNmzaxceNGzjnnHGpra1mwYMGg11bIkYkfBl539y0AZnY/8AHgrr2+agASZqSzunKAyLD32PXw9suD+56Hngizb+rz6fzTnM6fP597772XF154AXdnzpw5PP3002zZsoUJEybwyCOPAOE5QEaPHs0Pf/hDFixYQG1t7eDWHCmkj/pNYJaZVVl4VcZzgRXFKEbjqEUkDubPn8/8+fOZMWMGM2fOZOXKlaxevZoTTzyRJ554gq9//ev87ne/Y/To0UNSzz5b1O7+vJndCywG0sASoi6OwRboEHIRgb22fIeCu3PDDTdw1VVX9Xhu8eLFPProo3zjG9/g3HPP5Vvf+lbR6ylo1Ie7f9vdj3X3ae7+OXdvLUYxCR1CLiIlkn+a04985CPccccdNDU1AbBhwwY2b97Mxo0bqaqq4vLLL+e6665j8eLFPV5bDLE7e566PkSkFPJPczp79mwuu+wyTjvtNABGjBjBXXfdxZo1a7juuusIgoBUKsWtt94KwNy5c7nggguYMGFCUXYmmhfhAJP6+npvaGjo9+vm3tnAm9uaefyaMwe9JhGJtxUrVnDccceVuowh0dt3NbNF7l7f2/KxOteHWtQiIj3FKqgDXdxWRKSHWAV1Qhe3FRnWitEVGzcD+Y7xCmq1qEWGrYqKCrZu3XpQh7W7s3XrVioq+ncC0liN+gjM0IGJIsPTpEmTaGxsZKDnCjpQVFRUMGnSpH69JlZBnQjQzkSRYSqVSjF16tRSlxFL6voQEYm5WAV1oJ2JIiI9xCqo1aIWEekpVkEd6MIBIiI9xCqoE4G6PkREuotdUKvrQ0Skq1gFtcZRi4j0tM+gNrNjzGxp3m2nmV1TjGISAWpRi4h0U8gVXl4FpgOYWQLYADxQjGJ0FXIRkZ762/VxLrDW3d8oSjGBAbrKi4hIvv4G9aXAPb09YWZzzazBzBoGeqx+wsKgVveHiEingoPazMqAOcBvenve3ee5e72719fV1Q2smKhFre4PEZFO/WlRzwYWu/umYhWTzHV9qEUtItKhP0H9Gfro9hgsCbWoRUR6KCiozawaOA+4v6jFWG5nYjE/RUTkwFLQ+ajdfTdQU+RaOlvU6voQEekQryMT1fUhItJDrII6NzxPOxNFRDrFK6ijatJqUYuIdIhVUHfuTFRQi4jkxCqoNTxPRKSneAa1+qhFRDrEKqjV9SEi0lOsglotahGRnmIV1LkWtfqoRUQ6xSqoE4EOIRcR6S5mQR3eq+tDRKRTrIJaXR8iIj3FKqgTOh+1iEgP8QpqtahFRHqIVVDr4rYiIj3FKqg1jlpEpKdCr/AyxszuNbOVZrbCzE4rSjHq+hAR6aGgK7wA/ww87u6fjq5GXlWMYrQzUUSkp30GtZmNBs4ErgRw9zagrRjFdO5MLMa7i4gcmArp+pgKbAH+3cyWmNm/RRe77cLM5ppZg5k1bNmyZWDF5A54UdeHiEiHQoI6CcwEbnX3GcBu4PruC7n7PHevd/f6urq6ARWjrg8RkZ4KCepGoNHdn48e30sY3INO46hFRHraZ1C7+9vAejM7Jpp1LrC8KMWoRS0i0kOhoz7+Erg7GvHxGvBnxShGLWoRkZ4KCmp3XwrUF7kWXTNRRKQXsTwyUV0fIiKdYhnUGkctItIpVkHdcQi5WtQiIh1iFdQJnT1PRKSHeAW1Rn2IiPQQq6DOHUKunYkiIp1iFdQanici0lOsglo7E0VEeopVUGtnoohIT/EKap2PWkSkh1gFdaBrJoqI9BCroIaw+yOTVZNaRCQnfkFtpq4PEZE8sQvqINA4ahGRfLEL6rBFraAWEckp6HzUZrYO2AVkgLS7F+3c1EGgoBYRyVfoFV4AznH3d4pWSSQRmLo+RETyqOtDRCTmCg1qB+ab2SIzm9vbAmY218wazKxhy5YtAy9ILWoRkS4KDeoz3H0mMBv4ipmd2X0Bd5/n7vXuXl9XVzfggtSiFhHpqqCgdvcN0f1m4AHg1GIVFB7wUqx3FxE58OwzqM2s2sxG5qaB84FlRStI46hFRLooZNTHIcADFp4wKQn80t0fL1ZB6voQEelqn0Ht7q8BJw1BLUA0jlotahGRDrEcnqfzUYuIdIpfUOvIRBGRLmIX1IFpHLWISL7YBXUyoRa1iEi+2AV1YEZGOS0i0iF2QZ0ItDNRRCRf/IJa46hFRLqIXVAHgS5uKyKSL3ZBra4PEZGuYhfU4c5EBbWISE7sglotahGRruIX1GpRi4h0EbugDnQ+ahGRLmIX1Dopk4hIV/ELap3mVESki9gFdaCdiSIiXRQc1GaWMLMlZvZwMQtKmA54ERHJ158W9dXAimIVkhPofNQiIl0UFNRmNgn4KPBvxS1HOxNFRLortEV9M/DXQJ8D58xsrpk1mFnDli1bBlyQdiaKiHS1z6A2s48Bm9190d6Wc/d57l7v7vV1dXUDL0hdHyIiXRTSoj4dmGNm64BfAR8ys7uKVZBOcyoi0tU+g9rdb3D3Se4+BbgU+G93v7xYBenitiIiXcVvHLUZymkRkU7J/izs7guBhUWpJJIIUItaRCRP/FrUGvUhItJF7IJa46hFRLqKX1CrRS0i0kXsgjowwx1cYS0iAsQwqBOBAdqhKCKSE9+gVotaRASIcVBndTkuEREgjkFtalGLiOSLXVAH6qMWEekidkE9siI8WHLTzpYSVyIiEg+xC+rTj6oFYOGrm0tciYhIPMQuqCeOqeTYQ0fy3ysV1CIiEMOgBjj7mPE0rHuXnS3tpS5FRKTkYhnUHzp2POms88zqd0pdiohIycUyqGdOHsOoiiRPvTrway+KiBwsCrlmYoWZvWBmL5nZK2Z2Y7GLSiYCTpkyjhff2FbsjxIRib1CWtStwIfc/SRgOnCBmc0qbllQP2Ucr23Zzdam1mJ/lIhIrBVyzUR396boYSq6Ff1olPopYwFY9Ma7xf4oEZFYK6iP2swSZrYU2Aw84e7P97LMXDNrMLOGLVv2v2/5xImjKUsECmoRGfYKCmp3z7j7dGAScKqZTetlmXnuXu/u9XV1dftdWEUqwYmTRvPiOvVTi8jw1q9RH+6+HVgAXFCccrqqnzKWlzfsoKU9MxQfJyISS4WM+qgzszHRdCVwHrCy2IUBzJpaQ3vG1aoWkWGtkBb1YcACM/sj8CJhH/XDxS0rNOuIGsqTgQ4nF5FhrZBRH3909xnu/j53n+bufzsUhQFUliU47cgaFiioRWQYi+WRifk+dOx41m1t5vV3dpe6FBGRkoh9UJ9zzHgAdX+IyLAV+6A+fFwVxxwykoeWbsB1eS4RGYZiH9QAn501mZcad7D4TR38IiLDzwER1J+aOYlRFUl++szrpS5FRGTIHRBBXV2e5DPvn8zjy95mzeamfb9AROQgckAENcAXz5jKyIoU1937kq5QLiLDygET1ONHVvC3F53Akje3c+vCNaUuR0RkyBwwQQ0w56QJfPykCfzgiVU8/MeNpS5HRGRIJEtdQH+YGf/w6ffx9o49XPsfL1FTXc5pR9aUuiwRkaI6oFrUEJ7+9PbP1zO5poq5v2hg5ds7S12SiEhRHXBBDTCmqoyff+FUqsuSXHHHC2zYvqfUJYmIFM0BGdQAE8dU8rMvnEJzW4Yr7niBd3RtRRE5SB2wQQ1w7KGjmPe5etZva2bOvzzDHxu3l7okEZFBd0AHNcBpR9Zw359/ADPjstufZ9mGHaUuSURkUB3wQQ0wbeJo7vvzDzC6MsWV//6CwlpEDiqFXIrrcDNbYGbLzewVM7t6KArrr0NHV3DnF08lERgX3/J7bntqrc62JyIHhUJa1Gng/7j78cAs4CtmdnxxyxqYI+tG8F/XnMn5JxzCTY+t5AfzVymsReSAV8iluN5y98XR9C5gBTCx2IUN1JiqMn78mZlcesrh/HjBGm78z+WkM9lSlyUiMmD9OjLRzKYAM4Dne3luLjAXYPLkyYNQ2sAFgfHdT5xIdXl4atQ1m5v48WUzGFNVVtK6REQGouCdiWY2ArgPuMbdexwO6O7z3L3e3evr6uoGs8YBCQLjmx87nu9/+n288Po2Lr7l96zZvKvUZYmI9FtBQW1mKcKQvtvd7y9uSYPrkvrDuWfu+2lqzXDxLc/y3ys3lbokEZF+KWTUhwE/BVa4+w+LX9LgO/k943joL05nSm0VX/x5g0aEiMgBpZAW9enA54APmdnS6HZhkesadBPGVPKbqz7AhScexk2PreQv71lCU2u61GWJiOzTPncmuvszgA1BLUVXWZbgx5+ZwQkTRvGP//Uqyzfu5JbPzuS4w0aVujQRkT4dFEcm9oeZ8eWzj+KXX5pFU2uai2/5Pfcvbix1WSIifRp2QZ0z64gaHvnqB5kxeQzX/volblmwRv3WIhJLwzaoAepGlnPnF97PnJMm8A//9Sp/9rMX2bSzpdRliYh0MayDGqAsGXDzn07nxjkn8NxrWzn/n57mwaUbSl2WiEiHYR/UEB4cc8UHpvDoVz/IEXXVXP2rpXzj/79Muw49F5EYUFDnOaJuBL+56jSuOusI7nruTeb8+Pc8sXyT+q5FpKQU1N0kEwE3zD6OWz87k+a2NF+6s4Ev372Y7c1tpS5NRIYpBXUfZp94GL+99ixumH0sT67YxAU3/45n175T6rJEZBhSUO9FMhFw1VlH8sCXT6eqLMFn/+15bnpsJW1p9V2LyNBRUBdg2sTRPPzVM7j0lMO57am1zPnxMzypvmsRGSLxCuqGO2DzilJX0auqsiR//8n3Me9zJ9PSnuF/3dnAFf/+Iuu3NZe6NBE5yMUnqFt2whPfhp/Mgl9/HtKtpa6oV+efcChPXHsW3/n48Sxat43z/+lpfvrM62Syal2LSHHEJ6grRsHVL8GZfw3LH4QF34Vtr8Fzt8H2NyGThq1rw3mZ0p71LpUIuPL0qcy/9ixmHTGOv3t4OR//l2d4cd22ktYlIgcnK0Y/a319vTc0NAz8DR76Kiz5BSQroX03BElIlEF71M0wsR6ufBhSlb2/ftfbsKMRJtUPvIYCuTuPvvw2//eR5by1o4WLp0/g67OP5bDRfdQmItILM1vk7r2GVjyDunUX3P4hGHEInPttWPlw2BVy6DTYvQWe/A6cdBlc/BPIpuHVR+Ho88Pgbt4Wvvbd12HG5fCRvw9b60XW3JbmJwvWMu/p18Dg87Pew5fPOYpx1bpOo4js234FtZndAXwM2Ozu0wr5wP0OaoBsFoI+emYW3gQL/x7OuDYM7iW/gPovwEe+C3d9GhpfhJMuDeePOwL+9C4Yf9z+1VOg9dua+effrub+xY1UphJ88YNH8MUzpjK6MjUkny8iB6b9DeozgSbgziEN6r3JZuGRv4JFPwsf1x4D77wK448PR4188nZ435/AG8/Cr68IW+jn3QinfKkz/NuaYetqOOykopS4ZvMufjB/FY8te5tRFUmuOutIrvzAFKrL+3XhdxEZJva768PMpgAPxyaoIQzrhd+FTBucdT3865mw/Q34xL/CtE92LrfrbXjoL2H1fJj+WbjoFlj5CDx+PexYD8fNgdnfh1GHwfoXIdsOk06FxOAE6rINO/inJ1bx25WbGVddxlVnHsGlp05WC1tEuhiSoDazucBcgMmTJ5/8xhtvDKjYAdu1CVp3Qu3RPZ9zD0eRPP19qDk6bEmPPx6OPi8cVWIBTJwJb/w+XD5VHfZ31xwJJ/5JGPBlVeFze96Fps0w7sh+hfmSN9/lh0+s4ner36EyleDiGRP5/Gnv0WXARAQ4WFvU/eUOj98AS++Gs6+HU+dCIgXbXg9D/PWn4f1zwwB+8zlIt8D6F2DzKzBqEky/DFp2wJK7wpEoqSr48I3ha/rh5cYd3PmHdTz00kZa01lOmjSaT588iY+fNIExVdrxKDJcKajzZTMQJApfft0zMP8bsHFJ2PI+4ZNw5DnwygOw5kk4+Uo47+86R5a4g+37WsDv7m7j/iUb+E3Dela+vYuyRMB5xx/CnOkTOP2oWkaoL1tkWFFQD4ZsBjwbtsJzj5/8Djz7L1BdB4eeGHaLbF4BR38Y3v/nsOaJcPhgzVFwzEdhRF2Pt3V3Xtm4k3sXNfLg0g2829xOMjBOfs9YznxvHWe9t45jDx1JMhGfY5NEZPDt76iPe4CzgVpgE/Btd//p3l5zUAZ1XxoXwVPfg+Z3oKwaxkyGl+8Nu06CJFgCMq3hfe3RUD4Kdm+Gw2fB7O9B5ZiOt2pLZ2l4YxtPr3qHp1dtYflbOwEoTwYce9gojj9sFEePH8HUumqOrB3B+FHlVKT68d+BiMTWgXfAy4Fu61pobICjPgxV42Dzclh2fziEsGVHGNavPgZVNVD73rCrJJsOD/AZPQlGTYSKUexIJ1mxNcOabRlWbsuw/J00W1oT7PAR7KQagJHlSWpGlFEzopxx1WXUjiijpjqcHlmRZGRFilHRffg4nC5LqoUuEicK6jha/yL8/ubwSEoI+813vRUe+p7e95XQ25IjaU6OptmqabIqdmYreDdTybZ0OVvay9nplTRRxS6vZBeV7PIqdlFFk1eyiyrak1VUlZdRVZaguixJdXmC6vJk3uMkVeXhdGUqQUUqoDyVoCKVoCIZUJFKUJYMwlui630qEU6nkkYqEZAMDCug315kONtbUGuPVakcfgpcenfP+e5hX3dbU3hQTvtuaN8TTUe35q2UbX+TsuZtjGndGR7Q07ITWjdA6w6cXZjv++IGLV7FnvZq9qSraNpTTROV7PRKdmQr2ZGpYFumgm3ZSpo6gr6SVk+RJkGaJK0kaSNFmydpJRVOk6KdBNA1mJOBkQiMZGAko/DOPU4kjGQQdD7Ov+++bBDkvabr/FSil+W6fEY4P7CwOjPDLLoHEt0/u1tNQTQdmEXLQiIISJgRBNHrLVwusHDaLLx4csKMIJrueC4gmh8ul4ieC6KaRHIU1HFjFnaXVI0b+Fu4Q9vucFx5R4jvyJveBa07qWjZSUXrLsZ2ee7tzmn2wAC6wB0jE5SRCVJkrIy0ldGSHEnaUqQye2gNKmkLKsAzmGfDbZNXsSdbRZunCNrT7LFKmqkk4W24O+2eIE2Cdg9o8yRtuXsStGUTtHqCNg9o9iRt2SB8nA1o94AM0a1jOtE5j4B2kuz2CgBSlqacdhyj1cMNTytJWimjjSQ+RCecNKNr2HcL+iAKdstNWzTdLfxzGxXr4zX5y+XfQ7d5dG7Ywg1d+FlGuNXLLZPbyLg7uTP/Brn6g6415G+8jM7Ptej7W7fv3vEde1kXuVpzn53rKOh4z9wGMG+aju+V/x3pqCW3Ac99z+7rxchtVMOqzaAileCs9/YcNLC/FNQHIzMoHxHe9kemPQrtHR3hTrolHPGSaQ93kqbbovvolmnF0m0k0y0kM23R/BZG7dkeHvWZqgw3Im3N4c7WIAiPMm1rgrat4fLJRLShaYJkWTgsMpMOX59Nh7e9yWVpEfazZi2JJ8rwbv8xgHc8nw1SuCUxT4M7banRpBMVOIZbQJYAJyBrhpMgi5G1cJ5jZMktE270cvdBNk3akuxK1dJOCicMpDRJMpYgmW2lzcposUpS2RYc6/gvp83KyHhAVXonCW8PN3okSXuSdhIkvR3HOzaQbaTCT402pFks2tCF9WWcaONnZKJ6025kMNIEGEH0ncLn27NG1o12NzJupKNbezZ6HH33jBuj2UWlt7CZMTR7OVk3Mu5k3MEhSYYy2kng7KacDAkCsrQSjsiqoI0WyvqxUXW6/wc4ULUjymn4xocH5b3yKailb4nUfrfui8I93FBk28NTCGTS4X22vet0Nh1uBLJp8Ez0OBMNtcx7nGmHtl2AhafTTZZHnxFuZPI3RkG6NXz/vuryTFRTW7ghAir2vBtugDwb3nJDPXs8bsublwU8fM/cfSIVvs/OJeH3y8m0hd8lWRnt3zjALmJhfUz3kxM2b82z4XSyPFqfuaZ9EizAg0Q4CitIQDaLte7AU5VkK8b2KMCh8/U9PtA7l4lkKscBCmqR8D+GZBlQBtHol2Evd6BVNhPu00hFpzzo2Ni0hhukyrGQrIg2atEtmw43Au7hPpHWpmhIaUBHcOVvWLpsXDJ5j73b47zn3ft4TS/vWTk2PGXDrk2Q3tP5/XKRmCiDRHn4fduawtdZgLXvCZcpqw6n0y1h/bk+i2gjbZ63scagcgzWvoegeS8X/uhzn0G3+UU6pbKCWuRg0NGBmuja5RVU9n6BjUSyjwtv1BSlPNk/GkwrIhJzCmoRkZhTUIuIxJyCWkQk5hTUIiIxp6AWEYk5BbWISMwpqEVEYq4opzk1sy3AQK9uWwu8M4jlDBbV1X9xrU119Y/q6r+B1PYed+/1jE5FCer9YWYNfZ2TtZRUV//FtTbV1T+qq/8GuzZ1fYiIxJyCWkQk5uIY1PNKXUAfVFf/xbU21dU/qqv/BrW22PVRi4hIV3FsUYuISB4FtYhIzMUmqM3sAjN71czWmNn1JazjcDNbYGbLzewVM7s6mv8dM9tgZkuj24Ulqm+dmb0c1dAQzRtnZk+Y2erofuwQ13RM3npZamY7zeyaUqwzM7vDzDab2bK8eb2uHwv9KPqd+6OZzSxBbf9gZiujz3/AzMZE86eY2Z68dXfbENfV58/OzG6I1tmrZvaRIa7rP/JqWmdmS6P5Q7m++sqI4v2ehVfsLe2N8DKka4EjCK+v9BJwfIlqOQyYGU2PBFYBxwPfAb4Wg3W1DqjtNu/7wPXR9PXA90r8s3wbeE8p1hlwJjATWLav9QNcCDxGeD2lWcDzJajtfCAZTX8vr7Yp+cuVoK5ef3bR38JLQDkwNfq7TQxVXd2e/wHwrRKsr74yomi/Z3FpUZ8KrHH319y9DfgVcFEpCnH3t9x9cTS9C1gBTCxFLf1wEfDzaPrnwMUlrOVcYK27D/TI1P3i7k8D3S9+19f6uQi400PPAWPM7LChrM3d57t77rLqzwGTivX5/alrLy4CfuXure7+OrCG8O93SOsyMwMuAe4pxmfvzV4yomi/Z3EJ6onA+rzHjcQgHM1sCjADeD6a9RfRvy53DHX3Qh4H5pvZIjObG807xN3fiqbfBg4pTWkAXErXP544rLO+1k/cfu++QNjyyplqZkvM7Ckz+2AJ6untZxeXdfZBYJO7r86bN+Trq1tGFO33LC5BHTtmNgK4D7jG3XcCtwJHAtOBtwj/7SqFM9x9JjAb+IqZnZn/pIf/a5VkzKWZlQFzgN9Es+KyzjqUcv3sjZn9DZAG7o5mvQVMdrDg0TYAAAH5SURBVPcZwLXAL82sOJe47l3sfnbdfIauDYIhX1+9ZESHwf49i0tQbwAOz3s8KZpXEmaWIvwB3O3u9wO4+yZ3z7h7FridIv27ty/uviG63ww8ENWxKfevVHS/uRS1EW48Frv7pqjGWKwz+l4/sfi9M7MrgY8Bn43+wIm6FrZG04sI+4LfO1Q17eVnV/J1ZmZJ4JPAf+TmDfX66i0jKOLvWVyC+kXgaDObGrXKLgUeKkUhUd/XT4EV7v7DvPn5fUqfAJZ1f+0Q1FZtZiNz04Q7opYRrqsrosWuAB4c6toiXVo5cVhnkb7Wz0PA56O98rOAHXn/ug4JM7sA+Gtgjrs3582vM7NENH0EcDTw2hDW1dfP7iHgUjMrN7OpUV0vDFVdkQ8DK929MTdjKNdXXxlBMX/PhmIvaYF7Ui8k3Hu6FvibEtZxBuG/LH8Elka3C4FfAC9H8x8CDitBbUcQ7nF/CXglt56AGuC3wGrgSWBcCWqrBrYCo/PmDfk6I9xQvAW0E/YFfrGv9UO4F/6W6HfuZaC+BLWtIey/zP2u3RYt+6noZ7wUWAx8fIjr6vNnB/xNtM5eBWYPZV3R/J8B/7vbskO5vvrKiKL9nukQchGRmItL14eIiPRBQS0iEnMKahGRmFNQi4jEnIJaRCTmFNQiIjGnoBYRibn/AYeNnkKMnmQlAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuwYtxd9Rse1",
        "outputId": "e4143770-176c-4bbc-80cb-e5ebc89b7fae"
      },
      "source": [
        "# make predictions\n",
        "trainPredict = model.predict(x_train)\n",
        "testPredict = model.predict(x_test)\n",
        "print(\"trainPredict = \",trainPredict.shape)\n",
        "print(\"\\ntestPredict = \",testPredict.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainPredict =  (91701, 1, 4)\n",
            "\n",
            "testPredict =  (22926, 1, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hb4O8QkBXcC",
        "outputId": "e712fb6d-dd20-4f30-d62b-bcab26437a70"
      },
      "source": [
        "print(\"trainPredict Type - \",type(trainPredict))\n",
        "print(\"testPredict Type - \",type(trainPredict))\n",
        "y_pred_train = trainPredict.reshape(-1,4)\n",
        "y_pred_test = testPredict.reshape(-1,4)\n",
        "print(\"y_pred_train  - \",y_pred_train.shape)\n",
        "print(\"testPredict  - \",y_pred_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainPredict Type -  <class 'numpy.ndarray'>\n",
            "testPredict Type -  <class 'numpy.ndarray'>\n",
            "y_pred_train  -  (91701, 4)\n",
            "testPredict  -  (22926, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ7LYrdp9UKA",
        "outputId": "a668d631-b20f-4270-9cc4-5116ae2f828d"
      },
      "source": [
        "from sklearn import metrics\n",
        "print(\"R2 score:\", metrics.r2_score(y_test, y_pred_test))\n",
        "print(\"R2 score:\", metrics.r2_score(y_train, y_pred_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 score: 0.44703779822863626\n",
            "R2 score: 0.4404734168983751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btkiNVWxF4y6",
        "outputId": "9d46bf41-ffe4-4114-d350-4c4a23b0845b"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "MAE_test = mae(y_test, y_pred_test)\n",
        "MAE_train = mae(y_train, y_pred_train)\n",
        "print(f\"MAE - Test ={MAE_test}\\nMAE - Train ={MAE_train}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE - Test =0.56009115783443\n",
            "MAE - Train =0.5612444765743427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpYCNYRID21Y",
        "outputId": "e3c03edd-dd47-4ca7-f869-dbfe4d7803e8"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[31.9390624, 32.9224336, 32.176928 , 32.5221232],\n",
              "       [32.7889968, 32.699072 , 33.4880896, 33.0007552],\n",
              "       [32.8412112, 32.6207504, 33.4880896, 32.9688464],\n",
              "       ...,\n",
              "       [29.4617792, 29.2703264, 29.5836128, 29.3747552],\n",
              "       [32.7338816, 32.5656352, 33.4010656, 32.8035008],\n",
              "       [32.0144832, 32.8122032, 32.2378448, 32.4728096]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hly3xO1MD70F",
        "outputId": "9f4b159c-a539-4b19-c42e-38e1c269e2ba"
      },
      "source": [
        "y_pred_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[32.205364, 32.794266, 32.494926, 32.604702],\n",
              "       [32.82759 , 32.61466 , 33.523373, 32.90305 ],\n",
              "       [32.684235, 32.639996, 33.315838, 32.825794],\n",
              "       ...,\n",
              "       [31.305182, 32.45251 , 31.15049 , 32.023228],\n",
              "       [31.828745, 32.35096 , 32.011654, 32.237072],\n",
              "       [32.0456  , 32.79992 , 32.2786  , 32.48357 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KTy7bSLEAQO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}